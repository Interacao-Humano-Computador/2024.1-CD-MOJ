# Planejamento do Relato dos Resultados da Avaliação - Análise de Tarefas

## <a> Introdução </a>
Este documento se baseia no [Planejamento da avaliação](https://github.com/Interacao-Humano-Computador/2024.1-CD-MOJ/blob/git-pages/docs/design-avaliacao-desenvolvimento/nivel1/analiseTarefas/planejamentoAvaliacao.md). Sua principal função é organizar e sistematizar a disposição dos dados coletados durante a fase de avaliação dessa análise. O planejamento descrito aqui resultará na elaboração do relatório de resultados, onde serão apontados os pontos de melhoria para o CD-MOJ.

## <a> Metodologia </a>
Com base no documento de [Planejamento da avaliação](https://github.com/Interacao-Humano-Computador/2024.1-CD-MOJ/blob/git-pages/docs/design-avaliacao-desenvolvimento/nivel1/analiseTarefas/planejamentoAvaliacao.md), nos elementos de avaliação citados por Barbosa <a id="anchor_1" href="#REF1">^1^</a>, e na estrutura do relato dos resultados, de acordo com os requisitos da entrega 4 iremos construir o relato de resultados <a id="anchor_2" href="#REF2">^2^</a>. A tabela 1 a seguir mostra os componentes da avaliação:

<center>
  
<font size="3"><p style="text-align: center"><b>Tabela 1</b> - Componentes da Avaliação.</p></font>

| ID | Descrição | Avaliação | Observação |
| :-: | :-------- | --------- | ---------- |
| 1  | Possui o número e o perfil de avaliadores e dos participantes? |
| 2  | Possui as tarefas executadas pelos participantes? |
| 3  | Possui os objetivos da avaliação? |
| 4  | O artefato possui Introdução? |
| 5  | O artefato possui a metodologia utilizada? |
| 6  | O artefato possui referências bibliográficas/bibliografia? | 
| 7  | O artefato possui um histórico de versões (com versão, data, data de revisão, descrição, autor(es), revisor(es))? |
| 8  | As entrevistas das avaliaçoes foram gravadas? |
| 9  | Para a entrevista foram apresentados os modelos conceituais? |
| 10 | Possui uma breve descrição do método de prototipação em papel? |
| 11 | Possui a lista de problemas encontrados? |

_Fonte: [Luiz Gustavo](https://gith3ub.com/LuizGust4vo)_

</center>

## <a> Tópicos </a>
O relato dos resultados da avaliação da análise de tarefas deve incluir os seguintes tópicos <a id="anchor_3" href="#REF3">^3^</a>:

### <a> Objetivo e escopo da avaliação </a>
Nesta seção, o autor do documento deve explicar a razão pela qual a avaliação está sendo realizada e os objetivos que o grupo espera atingir<a id="anchor_4" href="#REF4">^4^</a>.

**Exemplo de objetivo:**
"A avaliação da análise de tarefas foi realizada com o objetivo de identificar e compreender as dificuldades enfrentadas pelos usuários ao interagirem com o CD-MOJ. O escopo da avaliação incluiu a análise das principais tarefas executadas pelos usuários durante o uso do sistema. Os principais tópicos desta avaliação foram:

- Identificar barreiras de usabilidade que impactam a eficiência e a satisfação dos usuários;

- Compreender o fluxo de trabalho dos usuários e verificar a adequação do sistema às suas necessidades."

### <a> Método </a>
Descrever as atividades realizadas para a coleta de dados e como a avaliação foi conduzida.

**Exemplo de metódo:**

"A metodologia empregada para a avaliação da Análise de Tarefas incluiu várias atividades de coleta de dados, realizadas em etapas distintas:

- Entrevistas: Foram realizadas entrevistas com os usuários para entender suas expectativas e dificuldades ao utilizar o sistema;
 
- Observação Direta: Observamos os usuários executando tarefas específicas no sistema, anotando cada etapa do processo e dificuldades encontradas;

- Questionários: Aplicamos questionários pós-uso para os usuários, a fim de coletar feedback sobre a experiência geral com o sistema.

Cada uma dessas atividades forneceu dados valiosos que, combinados, permitiram uma análise robusta das tarefas executadas pelos usuários."

### <a> Sumário de avaliadores e participantes </a>
Além de apresentar o cronograma executado, é necessário um resumo que identifique os participantes e descreva o perfil de cada um deles, proporcionando uma visão geral do público entrevistado.

**Exemplo de sumário de avaliadores e participantes:**

"O estudo contou com a participação de uma equipe composta por:

- Avaliadores: Três especialistas em usabilidade e um analista de sistemas;

- Participantes: 10 usuários divididos em dois grupos principais:

Grupo 1: 5 usuários experientes, com mais de dois anos de uso do sistema.

Grupo 2: 5 novos usuários, com menos de seis meses de uso do sistema.

Os participantes variam em termos de idade, ocupação e nível de habilidade técnica, garantindo uma amostra representativa da base de usuários do sistema."

### <a> Sumário de dados </a>
Neste tópico, o avaliador deve apresentar os dados coletados de forma resumida, objetiva e clara.

**Exemplo de sumário de dados:**

"Os dados coletados foram sintetizados nas seguintes categorias principais:

- Frequência de erros: Identificamos uma média de 3,5 erros por tarefa, com a maior concentração de erros ocorrendo durante a fase de entrada de dados;

- Tempo de execução das tarefas: O tempo médio para a conclusão das tarefas foi de 12 minutos, com uma variação significativa entre usuários experientes e novos;

- Feedback dos usuários: 65% dos usuários relataram dificuldades em localizar funções específicas no sistema, enquanto 80% dos novos usuários mencionaram a falta de orientações claras."

### <a> Análise dos dados coletados </a>
Aqui, será realizada a interpretação dos dados obtidos. É essencial incluir uma lista de problemas encontrados, categorizada de forma a permitir a rastreabilidade<a id="anchor_5" href="#REF5">^5^</a>.

**Exemplo análise dos dados coletados:**

"A análise dos dados coletados revelou vários problemas críticos de usabilidade, incluindo:

- Dificuldades na navegação: Muitos usuários tiveram problemas para localizar funções essenciais;

- Erros frequentes na entrada de dados: Usuários frequentemente cometiam erros ao inserir informações, devido a uma interface pouco intuitiva;

- Falta de feedback do sistema: Em vários casos, o sistema não fornecia feedback adequado após a execução de ações importantes, levando à confusão e repetição de tarefas.

Cada problema identificado foi categorizado por gravidade (alto, médio, baixo) e frequências de ocorrência, facilitando a priorização das soluções."

### <a> Sugestões de melhoria </a>
Finalmente, aqui devem ser propostas soluções para cada problema identificado, indicando a prioridade de cada sugestão de correção. Essas melhorias visam não apenas corrigir os problemas identificados, mas também otimizar a experiência geral do usuário com o sistema<a id="anchor_6" href="#REF6">^6^</a>.

**Exemplo de sugestões de melhoria:**

"Com base nos problemas identificados, foram sugeridas as seguintes melhorias, organizadas por prioridade:

Melhoria da Navegação (Prioridade Alta):

- Redesenho do menu principal para maior visibilidade das funções mais usadas.

- Implementação de uma barra de pesquisa inteligente.

Aprimoramento da Interface de Entrada de Dados (Prioridade Média):

- Simplificação dos formulários de entrada de dados, com validações em tempo real para reduzir erros.

- Inclusão de instruções contextuais para auxiliar os usuários durante o processo de entrada de dados.

Feedback do Sistema (Prioridade Alta):

- Adição de mensagens de confirmação e feedback visual após a realização de ações críticas.

- Desenvolvimento de um sistema de notificações que informe o usuário sobre o status das suas ações."

## <a> Referências Bibliográficas </a>
> <a id="REF1" href="#anchor_1">1.</a> BARBOSA, Simone; DINIZ, Bruno. Interação Humano-Computador, Editora Elsevier, Rio de Janeiro, 2010.
> 
> <a id="REF2" href="#anchor_2">2.</a> Plano de Ensino da disciplina Interação Humano Computador, Dr. André Barros de Sales. [Plano de Ensino](https://aprender3.unb.br/pluginfile.php/2843624/mod_resource/content/48/Plano_de_Ensino%20FIHC%20012024%20Turma%201.pdf).
>
> <a id="REF3" href="#anchor_3">3.</a> Lichess. Repositório do Grupo Lichess da disciplina de Interação Humano Computador da Universidade de Brasília, 2022. Disponível em: <https://github.com/Interacao-Humano-Computador/2022.2-Lichess/blob/main/docs/design_avaliacao_desenvolvimento/nivel_1/analise_tarefas/planejamento_resultado_analise_tarefas.md>.
>
> <a id="REF4" href="#anchor_4">4.</a> Nielsen, J. (1994). Usability Engineering. San Francisco: Morgan Kaufmann.
>
> <a id="REF5" href="#anchor_5">5.</a> Nielsen, J., & Landauer, T. K. (1993). A mathematical model of the finding of usability problems. Proceedings of the INTERACT '93 and CHI '93 Conference on Human Factors in Computing Systems.
>
> <a id="REF6" href="#anchor_6">6.</a> Norman, D. A. (2013). The Design of Everyday Things: Revised and Expanded Edition. Basic Books.


## <a> Bibliografia </a>
> Ventoy. Repositório do Grupo Ventoy da disciplina de Interação Humano Computador da Universidade de Brasília, 2023. Disponível em: <https://github.com/Interacao-Humano-Computador/2023.2-Ventoy/blob/main/docs/verificacao/DAD/nivel01/analiseDeTarefas/relatoResultados.md>. Acesso em: 22 de Maio 2024.

## <a> Histórico de Versão </a>

| Versão | Data | Data Prevista de Revisão | Descrição | Autor(es) | Revisor(es) |
| ------- | ------ | ------ | ------- | -------- | -------- |
| `1.0` | 18/05/2024 | 19/05/2024 | Criação do documento | [João Artur](https://github.com/joao-artl) | [Diego Sousa](https://github.com/DiegoSousaLeite) |
| `1.1` | 22/05/2024 | 22/05/2024 | Adição do Planejamento do Relato dos Resultados da Avaliação | [Luiz Gustavo](https://gith3ub.com/LuizGust4vo) | [Eric Silveira](https://github.com/ericbky) e [João Artur](https://github.com/joao-artl) |
| `1.2` | 23/05/2024 | 23/05/2024 | Adição dos exemplos de cada tópico | [Luiz Gustavo](https://gith3ub.com/LuizGust4vo) | [Eric Silveira](https://github.com/ericbky) e [João Artur](https://github.com/joao-artl) |
