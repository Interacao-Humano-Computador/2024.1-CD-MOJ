# Planejamento da Avaliação do Protótipo de Papel

## <a> Introdução </a>
A prototipação em papel é um método eficaz para avaliar a usabilidade de um design de Interface Humano-Computador (IHC) antes de desenvolver uma solução executável. Esse método envolve criar representações em papel e testá-las com potenciais usuários, permitindo identificar rapidamente problemas de usabilidade. Segundo Barbosa et al. (2021)<a id="anchor_1" href="#REF1">^1^</a>, é especialmente útil para avaliações formativas e comparação de alternativas de design, permitindo testar soluções parciais e de baixa fidelidade de maneira eficiente e econômica.

## <a> Metodologia </a>

O framework DECIDE, criado por Sharp, Rogers e Preece<a id="anchor_2" href="#REF2">^2^</a>, fornece um guia detalhado para o planejamento, execução e análise de avaliações de Interação Humano-Computador (IHC).Esse framework possui atividades interligadas e executadas iterativamente, com os objetivos articulados a partir do avaliador a partir dos recursos disponíveis<a id="anchor_3" href="#REF3">^3^</a>. Ele nos oferece a lista de checagem correspondente sobre o que está sendo avaliado, conforme a tabela1 representada a seguir:

<font size="3"><p style="text-align: center"><b>Tabela 1</b> - Lista de checagem do framework DECIDE.</p></font>

|Letra	|Definição|
|-------|---------| 
|D	|Determinar as metas que a avaliação irá abordar.|
|E	|Explorar as questões específicas a serem respondidas com a avaliação.|
|C	|Escolher o paradigma de avaliação e as técnicas de respostas para as perguntas.|
|I	|Identificar as questões práticas que devem ser abordadas, como a seleção dos participantes.|
|D	|Decidir como lidar com as questões éticas.|
|E	|Avaliar, interpretar e apresentar os dados.|

<font size="3"><p style="text-align: center"><b>Fonte:</b> Design de Interação: Além da Interação Humano-Computador. Capítulo 11.3: DECIDE: um framework para orientar a avaliação<a id="anchor_2" href="#REF2">^2^</a>.</p></font>

## <a> Framework DECIDE </a>

### <a>D - Determinar os Objetivos</a>
O processo de avaliação básica de um projeto de IHC consiste em três etapas, preparação, coleta e interpretação, o qual permitirá, por meio da análise dele, desenvolver melhorias de design para a aplicação estudada caso necessário<a id="anchor_4" href="#REF4">^4^</a>.

A avaliação tem como objetivo permitir que os entrevistados examinem os protótipos de papel criados para planejar sequências de eventos no CDMOJ. Esta análise visa identificar problemas nas narrativas das histórias, contribuindo para o aprimoramento do conteúdo. A partir dessa avaliação, espera-se que os participantes colaborem na refinamento, verificação e validação dos protótipos de papel, garantindo que eles estejam alinhados com a realidade atual da plataforma e atendam melhor às necessidades dos usuários. Além disso, o feedback dos usuários será coletado por meio de pesquisas e entrevistas após as sessões de teste, fornecendo dados cruciais para a validação das mudanças sugeridas. Um cronograma definido orientará a realização das avaliações e a implementação das alterações, com critérios claros de aceitação para os protótipos de papel revisados, focando na precisão do conteúdo, relevância e facilidade de compreensão.

### <a>E - Explorar Perguntas </a>

A partir dos objetivos, foram elaboradas perguntas específicas para orientar a investigação e facilitar a análise crítica necessária. Essas perguntas auxiliam na operacionalização do processo de avaliação, permitindo a realização de um julgamento de valor sobre os aspectos analisados<a id="anchor_5" href="#REF5">^5^</a>. Veja na Tabela 2 o que se pretende obter como resposta após a aplicação do questionário.

<font size="3"><p style="text-align: center"><b>Tabela 2</b> - Questões para serem respondidas a partir da avaliação</p></font>

| Número | Pergunta | O que se espera? |
|--------|------| -----|      
| 1 | a | a    |                                                                          

<font size="3"><p style="text-align: center"><b>Fonte:</b> [João Artur](https://github.com/joao-artl).</p></font>

As perguntas selecionadas têm o objetivo de serem respondidas com esta avaliação e serão discutidas posteriormente no tópico [Roteiro de Perguntas](#roteiro-de-perguntas).

### <a>C - Escolher os Métodos </a>

Os métodos de investigação (inquiry) incluem o uso de questionários, realização de entrevistas, grupos de foco e estudos de campo, entre outros. Esses métodos permitem ao avaliador acessar, interpretar e analisar concepções, opiniões, expectativas e comportamentos dos usuários em relação a sistemas interativos. Especificamente, eles permitem investigar alternativas de design, problemas enfrentados pelos usuários, como eles utilizam a tecnologia existente e quais são suas expectativas para futuras interações com tecnologias atuais e novas.<a id="anchor_6" href="#REF6">^6^</a>

A escolha dos métodos de investigação foi baseada em critérios estratégicos e práticos. Em primeiro lugar, a familiaridade do nosso grupo com a plataforma foi um fator crucial. Esse conhecimento do CDMOJ nos permitiu desenvolver questionários e conduzir entrevistas de maneira mais informada e focada, aprimorando a relevância e a precisão das perguntas feitas aos entrevistados.

Além disso, a disponibilidade e acessibilidade de uma base de usuários ativa, dentro do contexto em que o CDMOJ é amplamente utilizado na FGA, facilitaram significativamente a logística para a condução de grupos de foco e estudos de campo. Esse acesso direto aos usuários permitiu a coleta de dados autênticos e imediatos sobre como eles interagem com o sistema, bem como suas verdadeiras necessidades e dificuldades

Esses métodos foram escolhidos não só por sua eficácia em obter feedback detalhado e qualitativo, mas também pela capacidade de explorar profundamente as dinâmicas de uso do sistema. Isso foi importante para identificar não apenas as necessidades atuais, mas também para antecipar demandas futuras e ajustar o desenvolvimento dos protótipos de papel.

### <a>I - Identificar Questões Práticas </a>

#### <a>Recrutamento e Local</a>
É crucial selecionar participantes que possuam um perfil alinhado às demandas específicas e realidades do sistema. Para isso, utilizamos o artefato [Perfil De Usuário](https://interacao-humano-computador.github.io/2024.1-CD-MOJ/analise-de-requisitos/perfildeUsuario/) como base fundamental para o recrutamento. Este perfil foi desenhado para refletir as características, necessidades e comportamentos típicos dos usuários do CDMOJ, garantindo que os insights coletados durante a avaliação sejam pertinentes e aplicáveis.

O recrutamento é realizado diretamente no contexto acadêmico, aproveitando a acessibilidade e a disponibilidade de uma base de usuários engajada. Isso facilita a logística das sessões de avaliação e assegura que os participantes estejam familiarizados com o sistema, o que é essencial para obter feedback autêntico e preciso.

Cada um dos seis integrantes do nosso grupo desenvolveu um protótipo de papel, resultando em seis protótipos a serem avaliados. Para garantir uma análise abrangente e detalhada, recrutamos seis pessoas para o processo de entrevista, onde cada entrevistado será responsável por analisar um protótipo. Essa divisão estratégica maximiza a cobertura de feedback sobre os diferentes designs, mantendo uma carga gerenciável para cada participante.

As entrevistas para a avaliação dos protótipos criados para o CDMOJ serão conduzidas presencialmente. Esta abordagem permite uma interação direta e pessoal com os participantes, facilitando uma comunicação mais rica e detalhada. Realizando as sessões de avaliação presencialmente, poderemos observar reações físicas e capturar detalhes que podem não ser tão evidentes em avaliações online, enriquecendo o processo de análise e contribuindo para o refinamento do artefato.

#### <a>Roteiro de Perguntas</a>
Ao criar as perguntas, veja na tabela 3, levou-se em consideração o perfil e as atividades dos usuários-alvo para assegurar que a avaliação gere dados que contribuam significativamente para o refinamento do protótipo de papel.

<font size="3"><p style="text-align: center"><b>Tabela 3</b> - Roteiro de perguntas</p></font>

| Número | Pergunta | Resposta | Objetivo |
|--------|----------|----------|----------|
| ----- | ---- | ----- | -----|

<font size="3"><p style="text-align: center"><b>Fonte:</b> [João Artur](https://github.com/joao-artl).</p></font>

#### <a>Preparação</a>
O entrevistador terá um papel fundamental. Ele será responsável por conduzir as entrevistas seguindo um roteiro previamente definido, que contém perguntas detalhadas elaboradas para explorar a interação dos usuários com os protótipos de papel. Além de fazer as perguntas, o entrevistador também será responsável por registrar as respostas dos participantes, garantindo que todas as nuances e detalhes importantes sejam capturados.

As entrevistas incluirão interações diretas com os protótipos de papel criados, permitindo que os usuários demonstrem como navegam, interagem e interpretam as ilustrações. Isso proporcionará uma avaliação prática e dinâmica de como esses protótipos representam a experiência do usuário. Esta prática permitirá observar diretamente as interações dos usuários, coletando dados de observação comportamental ao longo do processo de avaliação. O entrevistador será um integrante do grupo que criou o protótipo de papel, responsável por conduzir as perguntas e registrar as respostas.

Por fim, antes de iniciar as entrevistas oficiais, um teste piloto será realizado com dois membros do grupo para testar o roteiro de perguntas e o processo de entrevista. Este piloto é essencial para identificar quaisquer áreas que possam precisar de ajustes e garantir que o instrumento de avaliação seja o mais eficaz e informativo possível.

#### <a>Custo</a>
As entrevistas para avaliação serão realizadas presencialmente na Universidade de Brasília - Faculdade do Gama (FGA). Essa escolha estratégica assegura a ausência de custos adicionais tanto para os participantes quanto para a equipe organizadora, já que todos os entrevistados são membros da FGA. As atividades serão conduzidas em espaços já disponíveis na universidade, eliminando a necessidade de aluguel de locais externos ou despesas com transporte, pois os participantes são locais. Realizar as sessões de forma presencial na própria faculdade não só minimiza os custos logísticos, mas também facilita a participação de todos os envolvidos, maximizando a conveniência e a eficácia da avaliação

#### <a>Equipamentos Necessários</a>
Durante a sessão, apenas o entrevistador precisará de dispositivos digitais básicos que suportem as funcionalidades necessárias para o registro e a condução efetiva da entrevista. Os equipamentos necessários incluem:

- Dispositivo Digital: Cada entrevistador usará um dispositivo digital, como um notebook ou smartphone, para acessar o roteiro de perguntas durante a entrevista. Este dispositivo ajudará o entrevistador a seguir a sequência de perguntas de forma organizada e precisa.
- Editor de Texto: O dispositivo do entrevistador também deve estar equipado com um editor de texto para registrar as respostas dos entrevistados. Isso é crucial para garantir que todos os detalhes importantes sejam documentados para análise posterior.
- Dispositivo de Gravação: Para capturar tanto o áudio quanto a imagem durante a entrevista, será necessário um dispositivo de gravação de qualidade. Esse equipamento é essencial para registrar a interação completa, permitindo que a equipe revise as entrevistas mais tarde para capturar nuances e detalhes que podem ser perdidos apenas nas notas escritas.

#### <a>Prazos</a>
Confira na Tabela 4, que apresenta o cronograma, como ficou definido o agendamento das entrevistas. Esta tabela detalha os horários de início e término, as datas, o storyboard que será usado pra ser analisado na entrevista e o local.

<font size="3"><p style="text-align: center"><b>Tabela 4</b> - Cronograma de entrevistas</p></font>

| Entrevistador | Entrevistado | Protótipo Analisado | Horário de Início | Horário de Fim | Data       | Local |
|-------------------|-----------------|----------------------|-------------------|----------------|------------|-------|
|- | - | - | - | - | - | - |

<font size="3"><p style="text-align: center"><b>Fonte:</b> [João Artur](https://github.com/joao-artl).</p></font>

#### <a>Recursos de mão-de-obra</a>
Para a realização eficaz das entrevistas, é essencial que o entrevistador esteja adequadamente equipado com todos os materiais necessários. O seguinte conjunto de recursos será necessário para a condução da entrevista:

- Protótipo de Papel Impresso: Cada entrevistador deverá ter em mãos uma cópia impressa do protótipo de papel. Este material será utilizado como base para a análise durante a entrevista, permitindo que o entrevistado visualize claramente os cenários discutidos.
- Lápis e Borracha: Para facilitar as anotações e possíveis alterações durante a análise do storyboard, lápis e borracha serão disponibilizados ao entrevistado. Isso permite que ele faça marcações ou correções diretamente no storyboard impresso.
- Papel A4: Além dos storyboards, papel A4 limpo será fornecido para que o entrevistado possa fazer rascunhos adicionais ou anotações detalhadas. Isso é particularmente útil para registrar insights ou expandir ideias que surgirem durante a entrevista.

### <a>D - Decidir as questões éticas</a>

O <a href="/2024.1-CD-MOJ/analise-de-requisitos/aspectosEticos/#termo-de-consentimento">termo de consentimento</a> apresentado no artefato <a href="/2024.1-CD-MOJ/analise-de-requisitos/aspectosEticos">Aspectos Éticos</a> assegura vários princípios fundamentais na condução de pesquisas envolvendo seres humanos, especialmente em contextos acadêmicos e de pesquisa. Os pilares principais que esse documento garante incluem:

- Voluntariedade: A participação na pesquisa é completamente voluntária, garantindo que os participantes têm a liberdade de escolher se envolver sem qualquer forma de coerção.
- Anonimato e Privacidade: Assegura que todas as informações coletadas durante a pesquisa serão tratadas com confidencialidade. Os dados pessoais dos participantes serão anonimizados, e apenas resultados agregados serão divulgados, protegendo a identidade e a privacidade dos envolvidos.
- Segurança: O documento afirma que a pesquisa não causará danos, prejuízos ou riscos à reputação ou emprego dos participantes, enfatizando a segurança dos envolvidos durante a participação no estudo.
- Transparência e Informação: Os participantes são informados sobre o objetivo da pesquisa, o que é essencial para garantir que eles tenham uma compreensão clara do que estão consentindo.
- Consentimento Informado: O termo inclui uma solicitação de assinatura para confirmar que o participante entende e concorda com os termos da pesquisa. No caso de menores de idade, é requerido o consentimento de um responsável legal, garantindo a observância de normas éticas adicionais.
- Responsabilidade: Designa o pesquisador responsável como ponto de contato, garantindo que haja um responsável direto pela integridade e pela condução ética da pesquisa.
- Gravações: Especifica a possibilidade de gravação das sessões como parte do método de coleta de dados, esclarecendo que estas serão utilizadas exclusivamente para fins de pesquisa, respeitando a privacidade e a finalidade do estudo.

Os entrevistados receberão informações completas sobre os termos da pesquisa e sua participação será iniciada somente após recebermos a sua expressa aprovação, veja na figura 1.

<center>
    <figure markdown>
    <font size="3"><p style="text-align: center"><b>Figura 1</b> -  Termo de consentimento para a avaliação.</p></font>
    ![Meta de usabilidade Aprendizagem](../../../../assets/termo.png){width: 300}
    </figure>

  <font size="3"><p style="text-align: center"><b>Fonte:</b> [Diego Sousa](https://github.com/DiegoSousaLeite).</p></font>
</center>

### <a>E - Avaliar, Interpretar e Apresentar os Dados</a>

Após a conclusão das entrevistas, os dados coletados serão cuidadosamente documentados e submetidos a uma análise detalhada. Esta etapa inclui uma avaliação rigorosa para assegurar a precisão e a relevância das informações obtidas.

Durante o processo, registraremos quaisquer problemas identificados, bem como as dificuldades encontradas pelos usuários durante a interação, incluindo questões relacionadas à interpretação e outros. Cada problema será descrito detalhadamente, classificado e acompanhado de sugestões de melhorias. Também captaremos o feedback dos usuários e, ao final de cada entrevista, documentaremos observações gerais relevantes.

Com base nessa análise minuciosa, os dados coletados serão utilizados para refinar e desenvolver os protótipos de papel, fornecendo insights essenciais que contribuirão significativamente para o seu aprimoramento.

### <a>Planejamento do Teste-Piloto</a>

Após a conclusão do planejamento, iremos utilizar como forma metodológica também o **teste-piloto**. Segundo Barbosa e Silva (2011, p.276), ele consiste em uma forma em que a equipe parametrize e faça uma verificação sobre a coleta dos dados, sobre como será conduziada a avaliação pelo avaliador e sobre as informações de orientação para com o participante, seguindo o planejamento de avaliação<a id="anchor_7" href="#REF7">^7^</a>.

De acordo com nosso planejamento, o teste-piloto será executado conforme as especificações da tabela 5 a seguir:

<font size="3"><p style="text-align: center"><b>Tabela 5</b> - Planejamento da entrevista do teste-piloto</p></font>

| Entrevistador | Entrevistado | Protótipo Analisado | Horário de Início | Horário de Fim | Data       | Local |
|-------------------|-----------------|----------------------|-------------------|----------------|------------|-------|
| [Eric Silveira](https://github.com/ericbky)      | [Diego Sousa](https://github.com/DiegoSousaLeite)    | --------   | 20:00         | 20:10      | 28/05  | Microsoft Teams   |

<font size="3"><p style="text-align: center"><b>Fonte:</b> [João Artur](https://github.com/joao-artl).</p></font>


### <a>Resultados do Teste-piloto</a>

A execução do teste-piloto ocorreu conforme o de planejamento e a tabela 6 descreve sobre a sua execução:

<font size="3"><p style="text-align: center"><b>Tabela 6</b> - Execução da entrevista do teste-piloto</p></font>

| Entrevistador | Entrevistado | Protótipo Analisado | Horário de Início | Horário de Fim | Data       | Local |
|-------------------|-----------------|----------------------|-------------------|----------------|------------|-------|
| [Eric Silveira](https://github.com/ericbky)      | [Diego Sousa](https://github.com/DiegoSousaLeite)    | --------   | 20:00         | 20:10      | 28/05  | Microsoft Teams   |

<font size="3"><p style="text-align: center"><b>Fonte:</b> [João Artur](https://github.com/joao-artl).</p></font>

O resultado que obtivemos sobre o teste-piloto está na gravação a seguir, conseguimos identificar os pontos de melhorias a serem abordados pela equipe e uma breve noção de como conduzir a avaliação.

#### <a>Gravação do Teste-Piloto</a>

link do video

## <a>Referências Bibliográficas</a>
>  <a id="REF1" href="#anchor_1">1.</a> BARBOSA, Simone Diniz Junqueira et al. Interação humano-computador e experiência do usuário. 1. ed. Rio de Janeiro: Simone Diniz Junqueira Barbosa, 2021.  Capítulo 10: Métodos de Avaliação de IHC. Página 358. Autopublicação. ISBN: 978-65-00-19677-1.

> <a id="REF2" href="#anchor_2">2.</a> Barbosa, S. D. J.; Silva, B. S. da; Silveira, M. S.; Gasparini, I.; Darin, T.; Barbosa, G. D. J. (2021) *Interação Humano-Computador e Experiência do usuário.* Capítulo 11 Planejamento da Avaliação de IHC, tópico 11.8 O Framework DECIDE, página 279 e 280. Autopublicação. ISBN: 978-65-00-19677-1.

> <a id="REF3" href="#anchor_3">3.</a> ROGERS, Yvonne. SHARP, Helen. PREECE, Jhennifer. Design de Interação: Além da Interação Humano-Computador. Capítulo 11.3: DECIDE: um framework para orientar a avaliação. Página 368.

> <a id="REF4" href="#anchor_4">4.</a> SIMONE DINIZ JUNQUEIRO BARBOSA, BRUNO SANTANA DA SILVA, Interação Humano-Computador, 1a. Edição, Editora Campus, 2010. (Versão grátis disponível em: https://docplayer.com.br/63299367-Interacao-humano-computador.html). Acessado em: 31/05/2024.

> <a id="REF5" href="#anchor_5">5.</a> Barbosa, S. D. J.; Silva, B. S. da; Silveira, M. S.; Gasparini, I.; Darin, T.; Barbosa, G. D. J. (2021) Interação Humano-Computador e Experiência do usuário. Capítulo 11 Planejamento da Avaliação de IHC, tópico 11.8 O Framework DECIDE, página 280. Autopublicação. ISBN: 978-65-00-19677-1.

> <a id="REF6" href="#anchor_6">6.</a> Barbosa, S. D. J.; Silva, B. S. da; Silveira, M. S.; Gasparini, I.; Darin, T.; Barbosa, G. D. J. (2021) Interação Humano-Computador e Experiência do usuário. Capítulo 11 Planejamento da Avaliação de IHC, tópico 11.6 Qual Tipo de Método de Avaliação Escolher?, página 272. Autopublicação. ISBN: 978-65-00-19677-1.

> <a id="REF7" href="#anchor_7">7.</a> Barbosa, S. D. J.; Silva, B. S. da; Silveira, M. S.; Gasparini, I.; Darin, T.; Barbosa, G. D. J. (2021) *Interação Humano-Computador e Experiência do usuário.* Capítulo 11, Planejamento da Avaliação de IHC, 11.7.2 Preparação, página 276. Autopublicação. ISBN: 978-65-00-19677-1.


## <a>Bibliografia</a>
> VIANNA, Maurício José; VIANNA, Ysmar; ADLER, Isabel Krumholz; LUCENA, Brenda de Figueiredo; RUSSO, Beatriz. Design Thinking: Inovação em Negócios. 1. ed. Rio de Janeiro: MJV Press, 2012. 162 p. ISBN 978-85-65424-00-4.
>
> Bilheteria Digital. Metas de usabilidade. Repositório do Grupo Bilheteria Digital da disciplina de Interação Humano Computador da Universidade de Brasília, 2023. Disponível em: <https://interacao-humano-computador.github.io/2023.1-BilheteriaDigital/design-avaliacao-desenvolvimento/nivel-2/prototipo-papel-dad/planejamento-avaliacao-pp/>. Acesso em: 29 de Maio 2024.

## <a>Histórico de Versão</a>

| Versão| Data | Data Prevista de Revisão| Descrição  | Autor(es)  | Revisor(es) |
| ------- | ------ | ------ | ------- | -------- | -------- |
| `1.0` | 29/05/2024 | 01/06/2024 | Criação do documento. | [Diego Sousa](https://github.com/DiegoSousaLeite)| [Douglas Marinho](https://github.com/M4RINH0) |
| `1.1` | 29/05/2024 | 01/06/2024 | Adicionando Introdução e titulos | [Diego Sousa](https://github.com/DiegoSousaLeite)| [João Artur](https://github.com/joao-artl) e [Luiz Gustavo](https://gith3ub.com/LuizGust4vo) |
| `1.2` | 31/05/2024 | 01/05/2024 | Adicionando framework DECIDE e perguntas do questionário| [João Artur](https://github.com/joao-artl)|[Diego Sousa](https://github.com/DiegoSousaLeite)|